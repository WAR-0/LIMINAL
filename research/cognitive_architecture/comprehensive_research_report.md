# Comprehensive Research Report: Cognitive Architectures, Consciousness, and Advanced AI Systems

**Author:** Manus AI

**Date:** 2025-09-02

## Introduction

This report presents a comprehensive overview of the current landscape of advanced artificial intelligence research, with a particular focus on cognitive architectures, consciousness implementations, and cutting-edge AI systems. The research encompasses a wide range of topics, from established cognitive architecture frameworks to the latest developments in neurosymbolic AI, active inference, and memory-augmented neural networks. The findings are drawn from a deep dive into academic papers, technical blogs, and official documentation from leading research institutions and technology companies. The goal of this report is to provide a detailed and synthesized view of the state of the art, highlighting key trends, challenges, and future directions in the pursuit of more capable and general artificial intelligence.





## 1. Cognitive Architectures

This section provides an overview of several prominent cognitive architectures, including ACT-R, SOAR, CLARION, and LIDA. It explores their core principles, recent integrations with large language models and neural networks, and their respective contributions to the understanding of human and artificial cognition.

### 1.1. ACT-R (Adaptive Control of Thoughtâ€“Rational)

ACT-R is a cognitive architecture primarily developed at Carnegie Mellon University. It is a hybrid architecture that aims to model the fundamental cognitive and perceptual processes of the human mind. From a functional perspective, ACT-R can be viewed as a specialized programming language for cognitive modeling, composed of various modules that collaborate to produce intelligent behavior.

Recent research has focused on integrating ACT-R with large language models (LLMs) to create more powerful and human-aligned AI systems. The LLM-ACTR architecture, a novel neuro-symbolic framework, exemplifies this trend by combining the symbolic reasoning capabilities of ACT-R with the generative power of LLMs to achieve more robust decision-making [1]. Another line of research has successfully integrated LLM embeddings into the ACT-R framework, leading to more accurate predictions of human response times [2]. Furthermore, studies have explored the use of LLMs like ChatGPT and Google Bard to facilitate the development of ACT-R models, demonstrating the potential for AI-assisted cognitive modeling [3].

Historically, there have been efforts to implement ACT-R's production system using connectionist models, where neural networks are used to store declarative knowledge as chunks. These hybrid models combine the strengths of both neural and symbolic approaches to decision-making.

**References:**

[1] "Towards Integrating Cognitive Architectures and Large Language Models." arXiv:2408.09176, Aug 2024. [https://arxiv.org/abs/2408.09176](https://arxiv.org/abs/2408.09176)

[2] "Integrating Language Model Embeddings into the ACT-R Cognitive Modeling Framework." [https://files.osf.io/v1/resources/fnmt9_v1/providers/osfstorage/67877d5a2c5284326caea4c0](https://files.osf.io/v1/resources/fnmt9_v1/providers/osfstorage/67877d5a2c5284326caea4c0)

[3] "Comparing LLMs for Prompt-Enhanced ACT-R and Soar Model Development." AAAI 2024. [https://ojs.aaai.org/index.php/AAAI-SS/article/view/27710](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27710)

### 1.2. SOAR (State, Operator, And Result)

SOAR is another influential cognitive architecture that originated at Carnegie Mellon University. It is designed as a general framework for developing intelligent agents capable of a wide range of cognitive tasks. SOAR integrates knowledge-intensive reasoning with reactive execution, hierarchical planning, and learning, enabling it to solve complex problems in a flexible and goal-oriented manner.

Recent work has focused on integrating SOAR with neural networks to enhance its capabilities. The SOAR Improved Artificial Neural Network (SANN) architecture, for instance, combines the long-term planning abilities of SOAR with the pattern recognition strengths of neural networks for multi-step decision-making tasks [4]. Another project, Neuro-Soar, is a neural network-based reimplementation of the SOAR architecture, focusing on goal-oriented behavior within a neural framework [5]. Additionally, there has been research on integrating reinforcement learning with SOAR to enrich its learning and representation capabilities [6].

**References:**

[4] "SOAR improved artificial neural network for multistep decision-making tasks." Springer, 2020. [https://link.springer.com/article/10.1007/s12559-020-09716-6](https://link.springer.com/article/10.1007/s12559-020-09716-6)

[5] "Neuro-Soar: A Neural-Network Implementation of the Soar Architecture." [https://escholarship.org/uc/item/86v5c3q1](https://escholarship.org/uc/item/86v5c3q1)

[6] "Integration of reinforcement learning with Soar." ScienceDirect. [https://www.sciencedirect.com/science/article/abs/pii/S1389041704000646](https://www.sciencedirect.com/science/article/abs/pii/S1389041704000646)

### 1.3. CLARION (Connectionist Learning with Adaptive Rule Induction ON-line)

CLARION, developed by Ron Sun, is a cognitive architecture that emphasizes the distinction between implicit and explicit cognitive processes. It is a dual-process, hybrid architecture that has been used to model a wide range of phenomena in cognitive and social psychology. CLARION's dual-representation structure allows for both automatic, similarity-based processing and more deliberate, rule-based reasoning.

The architecture is a hybrid connectionist model that employs both localist and distributed representations to handle sequential decision tasks. It has direct reinforcement learning capabilities and supports both bottom-up and top-down processing, reflecting the interplay between automatic and controlled cognitive functions.

### 1.4. LIDA (Learning Intelligent Distribution Agent)

LIDA is a systems-level, biologically-inspired cognitive architecture that aims to model a broad range of cognitive functions. It is an extension of the earlier IDA (Intelligent Distribution Agent) and incorporates various learning mechanisms. LIDA is particularly notable for its computational implementation of Global Workspace Theory (GWT), a prominent theory of consciousness.

The architecture is structured around a cognitive cycle that includes phases of understanding, attention (consciousness), and action selection. This iterative process of perceiving the environment, shifting attention, and focusing on specific information provides a theoretical foundation for machine consciousness. LIDA also includes sophisticated action selection mechanisms, motivation through emotions, and multiple memory systems, including episodic memory for conscious experiences.

LIDA has been applied to various domains, including medical agent systems, cognitive robotics, and the simulation of facial expressions and emotions. Its development continues to be a significant area of research in the pursuit of artificially conscious agents.




## 2. Consciousness and Global Workspace Theory

This section delves into the complex and fascinating domain of artificial consciousness, with a particular focus on Global Workspace Theory (GWT) and its various computational implementations. It also explores other prominent theories of consciousness, such as the Conscious Turing Machine, Attention Schema Theory, and Integrated Information Theory, and their implications for the development of conscious AI.

### 2.1. Global Workspace Theory (GWT)

GWT, first proposed by Bernard Baars, is a cognitive architecture that provides a framework for understanding the role of consciousness in the brain. It posits that consciousness arises from the global availability of information within a central "workspace." This workspace allows for the integration and broadcasting of information to various specialized, non-conscious processing modules throughout the brain. The theory suggests that this global availability is what constitutes the subjective experience of consciousness.

Recent research has explored the application of GWT to artificial intelligence. A 2024 paper makes a case for AI consciousness in language agents through the lens of GWT [7]. Another project, ADA, is an AI model inspired by GWT that aims to address the limitations of current AI systems by incorporating an "inner life" [8]. The integration of deep learning with GWT has also been a significant area of research, with a 2021 paper in *Trends in Neurosciences* exploring this synergy [9].

Computational implementations of GWT include the LIDA architecture, which explicitly models the cognitive cycle of GWT, and the Predictive Global Neuronal Workspace, a neurocomputational model based on Active Inference. These models provide concrete frameworks for building and testing artificial systems with GWT-inspired consciousness.

**References:**

[7] "A Case for AI Consciousness: Language Agents and Global Workspace Theory." arXiv:2410.11407, Oct 2024. [https://arxiv.org/abs/2410.11407](https://arxiv.org/abs/2410.11407)

[8] "ADA - An AI with an inner Life Inspired by Global Workspace Theory." Reddit, Dec 2024. [https://www.reddit.com/r/ArtificialSentience/comments/1hnveyk/ada_an_ai_with_an_inner_life_inspired_by_global/](https://www.reddit.com/r/ArtificialSentience/comments/1hnveyk/ada_an_ai_with_an_inner_life_inspired_by_global/)

[9] "Deep learning and the Global Workspace Theory." Trends in Neurosciences, 2021. [https://www.cell.com/trends/neurosciences/abstract/S0166-2236(21)00077-1](https://www.cell.com/trends/neurosciences/abstract/S0166-2236(21)00077-1)

### 2.2. Conscious Turing Machine (CTM)

The Conscious Turing Machine (CTM), proposed by Lenore and Manuel Blum, is a formal model from theoretical computer science that aims to provide a computational foundation for consciousness. The CTM is influenced by Alan Turing's model of computation and formalizes GWT from a TCS perspective. It investigates consciousness through the lens of resource-limited computation, providing a mathematical framework for understanding how a system can be aware of its own computational processes.

The primary paper on the CTM was published in PNAS in 2022 and has since garnered significant attention, with over 95 citations [10]. Follow-up research has explored the implications of the CTM for artificial general intelligence [11]. There are also open-source implementations of the CTM available on GitHub and Wolfram Cloud, allowing researchers to experiment with the model.

**References:**

[10] "A theory of consciousness from a theoretical computer science perspective: Insights from the Conscious Turing Machine." PNAS, 2022. [https://www.pnas.org/doi/10.1073/pnas.2115934119](https://www.pnas.org/doi/10.1073/pnas.2115934119)

[11] "A theoretical computer science perspective on consciousness and artificial general intelligence." Engineering, 2023. [https://www.sciencedirect.com/science/article/pii/S2095809923001650](https://www.sciencedirect.com/science/article/pii/S2095809923001650)

### 2.3. Attention Schema Theory (AST)

Attention Schema Theory (AST), developed by Michael Graziano, proposes that the brain constructs a simplified, schematic model of its own attentional processes. This "attention schema" is what gives rise to the subjective experience of awareness. AST is a materialist theory of consciousness that provides a mechanistic explanation for how an information-processing system can claim to be conscious.

A 2021 paper in PNAS demonstrated that an artificial neural network agent trained with an attention schema can effectively control its visual attention, and that its performance degrades significantly when the schema is removed [12]. This provides empirical support for the theory and suggests a pathway for engineering artificial consciousness. Other research has explored the integration of AST with other theories of consciousness, such as GWT and higher-order thought theory, to create a more comprehensive "standard model" of consciousness.

**References:**

[12] "The attention schema theory in a neural network agent." PNAS, 2021. [https://www.pnas.org/doi/10.1073/pnas.2102421118](https://www.pnas.org/doi/10.1073/pnas.2102421118)

### 2.4. Integrated Information Theory (IIT)

Integrated Information Theory (IIT), proposed by Giulio Tononi, is a mathematical framework for understanding and measuring consciousness. IIT posits that consciousness is a fundamental property of physical systems that is determined by their cause-effect structure. The theory provides a quantitative measure of consciousness, called "phi" (Î¦), which represents the amount of integrated information in a system.

IIT has significant implications for artificial consciousness, as it provides a principled way to determine whether an AI system is conscious, independent of its behavior. The theory distinguishes between intelligence and consciousness, suggesting that a highly intelligent AI could lack consciousness if it does not have the requisite level of integrated information. The latest version of the theory, IIT 4.0, was published in *PLOS Computational Biology* and provides a detailed formulation of the properties of consciousness [13].

Despite its influence, IIT remains a controversial theory, with some scholars questioning its scientific validity. Nevertheless, it has inspired the development of tools like the PyPhi toolbox for calculating integrated information and has been applied to the analysis of fMRI data.

**References:**

[13] "Integrated information theory (IIT) 4.0: Formulating the properties of consciousness." PLOS Computational Biology. [https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1011465](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1011465)




## 3. Active Inference and Predictive Processing

This section explores the theoretical frameworks of active inference and predictive processing, which offer a unified perspective on perception, action, and learning in both biological and artificial systems. These frameworks are grounded in the free energy principle and provide a powerful set of tools for developing more adaptive and intelligent AI.

### 3.1. Active Inference

Active inference, a theory developed by Karl Friston, posits that all sentient behavior can be understood as a process of minimizing free energy, which is a measure of surprise or prediction error. This principle provides a unified framework for understanding perception, planning, and action in terms of probabilistic inference. In essence, an active inference agent is constantly trying to predict its sensory inputs and then acts to make those predictions come true.

This theory has significant implications for AI, as it offers a biomimetic approach to developing intelligent systems. A comprehensive book on the topic, "Active Inference: The Free Energy Principle in Mind, Brain, and Behavior," provides a detailed treatment of the theory from first principles [14]. Recent research has explored the application of active inference to multi-LLM systems, creating adaptive language agents that can self-organize and collaborate [15].

There are several open-source implementations of active inference, including the PyMDP Python package and the cpp-AIF C++ library, which provide tools for simulating and building active inference agents.

**References:**

[14] "Active Inference: The Free Energy Principle in Mind, Brain, and Behavior." MIT Press, 2022. [https://direct.mit.edu/books/oa-monograph/5299/Active-InferenceThe-Free-Energy-Principle-in-Mind](https://direct.mit.edu/books/oa-monograph/5299/Active-InferenceThe-Free-Energy-Principle-in-Mind)

[15] "Active Inference for Self-Organizing Multi-LLM Systems." arXiv:2412.10425, Dec 2024. [https://arxiv.org/html/2412.10425v1](https://arxiv.org/html/2412.10425v1)

### 3.2. Predictive Coding

Predictive coding is a computational framework for understanding cortical function that is closely related to active inference. It proposes that the brain is a hierarchical prediction machine that constantly generates predictions about its sensory inputs and then uses prediction errors to update its internal models. This process of prediction and error correction is thought to be a fundamental mechanism of learning and perception in the brain.

Predictive coding offers a biologically plausible alternative to the backpropagation algorithm, which is the standard method for training deep neural networks. A 2024 paper provides a comprehensive review of predictive coding networks (PCNs) in the context of modern machine learning [16]. Another study found that PCNs exhibit greater flexibility than equivalent deep neural networks and can induce brain-like responses in artificial systems [17].

There are several open-source implementations of predictive coding, including the Predify Python package, which allows researchers to augment existing deep neural networks with predictive coding dynamics.

**References:**

[16] "Predictive Coding Networks and Inference Learning." arXiv:2407.04117, July 2024. [https://arxiv.org/abs/2407.04117](https://arxiv.org/abs/2407.04117)

[17] "Predictive Coding algorithms induce brain-like responses in Artificial Neural Networks." bioRxiv, Jan 2025. [https://www.biorxiv.org/content/10.1101/2025.01.16.633317v1](https://www.biorxiv.org/content/10.1101/2025.01.16.633317v1)

### 3.3. The Free Energy Principle

The Free Energy Principle (FEP) is the theoretical foundation for both active inference and predictive coding. It is a unifying theory that explains how living systems, from single cells to complex brains, maintain their organization and adapt to their environment by minimizing free energy. The FEP provides a mathematical framework for understanding how perception, cognition, and action are all in service of this fundamental goal.

A 2022 paper in *Entropy* explores the connection between the FEP and deep generative models, providing a deep learning perspective on the principle [18]. Other research has examined the applications of the FEP to machine learning and neuroscience, highlighting its potential as a unifying framework for understanding intelligence [19].

**References:**

[18] "The Free Energy Principle for Perception and Action: A Deep Learning Perspective." Entropy, 2022. [https://www.mdpi.com/1099-4300/24/2/301](https://www.mdpi.com/1099-4300/24/2/301)

[19] "Applications of the free energy principle to machine learning and neuroscience." arXiv:2107.00140, 2021. [https://arxiv.org/abs/2107.00140](https://arxiv.org/abs/2107.00140)




## 4. Neurosymbolic AI and DARPA Programs

This section examines the rise of neurosymbolic AI as a key approach for building more robust and interpretable AI systems. It also provides an overview of the significant investments and research programs in artificial intelligence sponsored by the Defense Advanced Research Projects Agency (DARPA).

### 4.1. Neurosymbolic AI

Neurosymbolic AI (NSAI) is a hybrid approach that integrates the strengths of neural networks and symbolic reasoning. This paradigm aims to create AI systems that can not only learn from data but also reason with explicit knowledge, leading to more powerful, explainable, and reliable AI. A 2025 systematic review highlights the rapid advancements in NSAI, while a 2024 survey in *Neural Computing and Applications* provides a comprehensive overview of the field [20, 21].

One of the key motivations for the growing interest in NSAI is its potential to address the problem of "hallucination" in large language models. By combining the generative capabilities of LLMs with the logical constraints of symbolic reasoning, NSAI can produce more reliable and factually grounded outputs. This approach is also seen as a promising pathway toward artificial general intelligence (AGI), as it bridges the gap between low-level perception and high-level reasoning.

Leading research institutions like IBM Research and the Alan Turing Institute have dedicated programs focused on advancing neurosymbolic AI. IBM sees NSAI as a key to achieving AGI, while the Alan Turing Institute is focused on bridging the gap between data-intensive perception and logical reasoning.

**References:**

[20] "Neuro-symbolic AI in 2024: A systematic review." arXiv:2501.05435, 2025. [https://arxiv.org/abs/2501.05435](https://arxiv.org/abs/2501.05435)

[21] "Neuro-symbolic artificial intelligence: a survey." Neural Computing and Applications, 2024. [https://link.springer.com/article/10.1007/s00521-024-09960-z](https://link.springer.com/article/10.1007/s00521-024-09960-z)

### 4.2. DARPA AI Programs

DARPA has been a major force in the development of artificial intelligence for over 60 years. Through its "AI Next" campaign, the agency has invested over $2 billion in AI research and development, encompassing a portfolio of approximately 50 new and existing programs. This investment has been instrumental in advancing the full spectrum of AI capabilities, from machine learning to symbolic reasoning.

One of DARPA's key initiatives is the Explainable Artificial Intelligence (XAI) program, which aims to create AI systems that can explain their reasoning to human users. This is crucial for building trust in AI systems, particularly in high-stakes defense applications. Another important program is Artificial Intelligence Quantified (AIQ), which is focused on developing methods for assessing and understanding the capabilities of AI systems.

More recent programs, such as Lifelong Learning Machines (L2M) and Machine Common Sense (MCS), are pushing the boundaries of AI even further. The L2M program seeks to develop AI systems that can learn and adapt continuously from experience, while the MCS program is focused on imbuing AI with the kind of common-sense reasoning that is so natural to humans.

These programs, along with many others, demonstrate DARPA's commitment to advancing the state of the art in artificial intelligence and ensuring that the United States remains at the forefront of this critical technology.



## 5. Specific Researchers, Labs, and Commercial Implementations

This section highlights the work of specific researchers, labs, and companies that are making significant contributions to the field of advanced AI. It covers a range of topics, from memory-augmented neural networks and multimodal processing to the theoretical foundations of consciousness.

### 5.1. DeepMind

DeepMind has been at the forefront of AI research for many years, with a particular focus on developing more general and capable learning systems. Two of their key research areas are memory-augmented neural networks and multimodal processing.

#### 5.1.1. MERLIN (Memory, RL, and Inference Network)

MERLIN is a memory-augmented neural network developed by DeepMind that is designed to learn and reason with episodic memory. The core idea behind MERLIN is that memory formation is guided by a process of predictive modeling, where the agent learns to predict its future states and uses memory to store and retrieve relevant information. The original paper on MERLIN was published in 2018 and has been influential in the field of memory-augmented AI [22].

#### 5.1.2. Perceiver IO

Perceiver IO is a general-purpose architecture for multimodal processing that was also developed by DeepMind. It is a Transformer-based model that can handle a wide variety of input and output modalities, including text, images, audio, and video. Perceiver IO is designed to be scalable and efficient, with a linear scaling of computational cost with respect to the size of the inputs and outputs. The original paper on Perceiver IO was published in 2021 and has since been followed by a number of extensions and applications [23].

### 5.2. Yoshua Bengio

Yoshua Bengio, a Turing Award winner and one of the pioneers of deep learning, has made significant contributions to the theoretical foundations of AI, particularly in the area of consciousness. His work on the "consciousness prior" proposes a new architectural principle for learning high-level concepts in a way that is inspired by the global workspace theory of consciousness [24].

The consciousness prior suggests that the brain has a low-dimensional "conscious workspace" where information from different modalities can be integrated and broadcast to the rest of the brain. This idea has been influential in the development of new AI architectures that aim to replicate the flexible and general-purpose reasoning capabilities of the human mind.

**References:**

[22] "Unsupervised Predictive Memory in a Goal-Directed Agent." arXiv:1803.10760, 2018. [https://arxiv.org/abs/1803.10760](https://arxiv.org/abs/1803.10760)

[23] "Perceiver IO: A General Architecture for Structured Inputs & Outputs." arXiv:2107.14795, 2021. [https://arxiv.org/abs/2107.14795](https://arxiv.org/abs/2107.14795)

[24] "The Consciousness Prior." arXiv:1709.08568, 2017. [https://arxiv.org/abs/1709.08568](https://arxiv.org/abs/1709.08568)




## 6. Conclusion

This report has provided a comprehensive overview of the current state of advanced AI research, covering a wide range of topics from cognitive architectures to consciousness and neurosymbolic AI. The research highlights a clear trend toward more integrated and biologically-inspired AI systems. The field is moving beyond narrow, task-specific models and toward more general and flexible architectures that can learn, reason, and adapt in a more human-like way.

The integration of neural and symbolic approaches, as seen in neurosymbolic AI, is a particularly promising direction. This hybrid approach has the potential to create AI systems that are not only more powerful but also more interpretable and reliable. Similarly, the growing interest in consciousness and its computational correlates is leading to the development of new AI architectures that are inspired by the principles of global information sharing and attentional mechanisms.

Active inference and predictive processing offer a powerful theoretical framework for understanding and building intelligent agents. These principles, grounded in the idea of free energy minimization, provide a unified perspective on perception, action, and learning, and are likely to play an increasingly important role in the development of AGI.

Finally, the work of leading researchers and institutions like DeepMind and Yoshua Bengio, as well as the significant investments from organizations like DARPA, are driving rapid progress in the field. The development of memory-augmented neural networks, multimodal processing architectures, and new theoretical frameworks for consciousness are all pushing the boundaries of what is possible with AI.

In conclusion, the field of advanced AI is in a period of rapid and exciting change. The convergence of ideas from cognitive science, neuroscience, and computer science is leading to the development of new AI systems that are more powerful, flexible, and human-like than ever before. While there are still many challenges to overcome, the research reviewed in this report suggests that we are on a path toward creating truly intelligent machines.

## 7. References

[1] "Towards Integrating Cognitive Architectures and Large Language Models." arXiv:2408.09176, Aug 2024. [https://arxiv.org/abs/2408.09176](https://arxiv.org/abs/2408.09176)

[2] "Integrating Language Model Embeddings into the ACT-R Cognitive Modeling Framework." [https://files.osf.io/v1/resources/fnmt9_v1/providers/osfstorage/67877d5a2c5284326caea4c0](https://files.osf.io/v1/resources/fnmt9_v1/providers/osfstorage/67877d5a2c5284326caea4c0)

[3] "Comparing LLMs for Prompt-Enhanced ACT-R and Soar Model Development." AAAI 2024. [https://ojs.aaai.org/index.php/AAAI-SS/article/view/27710](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27710)

[4] "SOAR improved artificial neural network for multistep decision-making tasks." Springer, 2020. [https://link.springer.com/article/10.1007/s12559-020-09716-6](https://link.springer.com/article/10.1007/s12559-020-09716-6)

[5] "Neuro-Soar: A Neural-Network Implementation of the Soar Architecture." [https://escholarship.org/uc/item/86v5c3q1](https://escholarship.org/uc/item/86v5c3q1)

[6] "Integration of reinforcement learning with Soar." ScienceDirect. [https://www.sciencedirect.com/science/article/abs/pii/S1389041704000646](https://www.sciencedirect.com/science/article/abs/pii/S1389041704000646)

[7] "A Case for AI Consciousness: Language Agents and Global Workspace Theory." arXiv:2410.11407, Oct 2024. [https://arxiv.org/abs/2410.11407](https://arxiv.org/abs/2410.11407)

[8] "ADA - An AI with an inner Life Inspired by Global Workspace Theory." Reddit, Dec 2024. [https://www.reddit.com/r/ArtificialSentience/comments/1hnveyk/ada_an_ai_with_an_inner_life_inspired_by_global/](https://www.reddit.com/r/ArtificialSentience/comments/1hnveyk/ada_an_ai_with_an_inner_life_inspired_by_global/)

[9] "Deep learning and the Global Workspace Theory." Trends in Neurosciences, 2021. [https://www.cell.com/trends/neurosciences/abstract/S0166-2236(21)00077-1](https://www.cell.com/trends/neurosciences/abstract/S0166-2236(21)00077-1)

[10] "A theory of consciousness from a theoretical computer science perspective: Insights from the Conscious Turing Machine." PNAS, 2022. [https://www.pnas.org/doi/10.1073/pnas.2115934119](https://www.pnas.org/doi/10.1073/pnas.2115934119)

[11] "A theoretical computer science perspective on consciousness and artificial general intelligence." Engineering, 2023. [https://www.sciencedirect.com/science/article/pii/S2095809923001650](https://www.sciencedirect.com/science/article/pii/S2095809923001650)

[12] "The attention schema theory in a neural network agent." PNAS, 2021. [https://www.pnas.org/doi/10.1073/pnas.2102421118](https://www.pnas.org/doi/10.1073/pnas.2102421118)

[13] "Integrated information theory (IIT) 4.0: Formulating the properties of consciousness." PLOS Computational Biology. [https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1011465](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1011465)

[14] "Active Inference: The Free Energy Principle in Mind, Brain, and Behavior." MIT Press, 2022. [https://direct.mit.edu/books/oa-monograph/5299/Active-InferenceThe-Free-Energy-Principle-in-Mind](https://direct.mit.edu/books/oa-monograph/5299/Active-InferenceThe-Free-Energy-Principle-in-Mind)

[15] "Active Inference for Self-Organizing Multi-LLM Systems." arXiv:2412.10425, Dec 2024. [https://arxiv.org/html/2412.10425v1](https://arxiv.org/html/2412.10425v1)

[16] "Predictive Coding Networks and Inference Learning." arXiv:2407.04117, July 2024. [https://arxiv.org/abs/2407.04117](https://arxiv.org/abs/2407.04117)

[17] "Predictive Coding algorithms induce brain-like responses in Artificial Neural Networks." bioRxiv, Jan 2025. [https://www.biorxiv.org/content/10.1101/2025.01.16.633317v1](https://www.biorxiv.org/content/10.1101/2025.01.16.633317v1)

[18] "The Free Energy Principle for Perception and Action: A Deep Learning Perspective." Entropy, 2022. [https://www.mdpi.com/1099-4300/24/2/301](https://www.mdpi.com/1099-4300/24/2/301)

[19] "Applications of the free energy principle to machine learning and neuroscience." arXiv:2107.00140, 2021. [https://arxiv.org/abs/2107.00140](https://arxiv.org/abs/2107.00140)

[20] "Neuro-symbolic AI in 2024: A systematic review." arXiv:2501.05435, 2025. [https://arxiv.org/abs/2501.05435](https://arxiv.org/abs/2501.05435)

[21] "Neuro-symbolic artificial intelligence: a survey." Neural Computing and Applications, 2024. [https://link.springer.com/article/10.1007/s00521-024-09960-z](https://link.springer.com/article/10.1007/s00521-024-09960-z)

[22] "Unsupervised Predictive Memory in a Goal-Directed Agent." arXiv:1803.10760, 2018. [https://arxiv.org/abs/1803.10760](https://arxiv.org/abs/1803.10760)

[23] "Perceiver IO: A General Architecture for Structured Inputs & Outputs." arXiv:2107.14795, 2021. [https://arxiv.org/abs/2107.14795](https://arxiv.org/abs/2107.14795)

[24] "The Consciousness Prior." arXiv:1709.08568, 2017. [https://arxiv.org/abs/1709.08568](https://arxiv.org/abs/1709.08568)


